<!DOCTYPE html>
<html lang="en">
<head>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-RF20TYVTHY"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-RF20TYVTHY');
  </script>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Alexandros Graikos</title>

  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>
<body>
  <div class="panel">
    <h1>Alexandros Graikos</h1>
    <div class="panel-content">
      <div class="text">
        <p>
        I am a PhD student at Stony Brook University, advised by 
        <a href="https://www3.cs.stonybrook.edu/~samaras/" target="_blank">Dimitris Samaras</a>.
        My research interests revolve around the <a href="https://arxiv.org/abs/2206.09012" target="_blank">rich image priors</a> encoded in deep generative models.
        More details about our work on learning and using such priors for the digital histopathology and satellite image domains <a href="https://histodiffusion.github.io/" target="_blank">here</a>.<br><br>
        I also interned at Microsoft Research where with my mentor 
        <a href="https://www.microsoft.com/en-us/research/people/jojic/" target="_blank">Nebojsa Jojic</a>
        we worked on interesting diffusion model prior problems.
        </p>
        <div class="links">
            <a href="mailto:agraikos@cs.stonybrook.edu" target="_blank">Email</a> / 
            <a href="https://github.com/AlexGraikos" target="_blank">GitHub</a> / 
            <a href="https://scholar.google.com/citations?user=1J7ZAUAAAAAJ" target="_blank">Google Scholar</a> /
            <a href="content/txt/cv.pdf" target="_blank">CV</a>
        </div>
      </div>
      <img src="content/img/me_cropped.jpg" alt="me?">
    </div>
  </div>


  <div class="header-panel">
    <h1>Selected Research</h1>
  </div>

  <!-- NewtonDiff -->
  <div class="publication">
    <div class="publication-content"> 
      <div class="gif-container">
        <img src="content/img/newton.png"
             data-animated="content/img/newton.gif"
             alt="GIF Toggle" id="newtonGIF">
      </div>

      <div class="text">
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2410.18804" target="_blank">
          <strong>Fast constrained sampling in pre-trained diffusion models</strong><br>
        </a>
        </p>
        <p class="authors">
        Alexandros Graikos,
        Nebojsa Jojic,
        Dimitris Samaras
        </p>
        <p class="venue">
        NeurIPS, 2025
        </p>
        <p class="description">
        We speed up training-free inference in diffusion models using an approximation to Newton's method. This is the algorithm that powers <a href="#zoomldmGIF">ZoomLDM</a>. We also made a short game that uses this algorithm to generate diffusion images in real-time
        [<a href="https://www.youtube.com/watch?v=DuxqX7DBC0g" target="_blank">Gameplay 1</a> /
        <a href="https://www.youtube.com/watch?v=SlyI0Gr-qpM" target="_blank">Gameplay 2</a>].
        </p>
        <div class="links">
          <a href="https://github.com/cvlab-stonybrook/fast-constrained-sampling" target="_blank">Code</a> /
          <a href="https://arxiv.org/abs/2410.18804" target="_blank">arXiv</a>
        </div>
      </div>
    </div>
  </div>
  <script>
    const gif_newton = document.getElementById("newtonGIF");
    const staticSrc_newton = gif_newton.src;
    const animatedSrc_newton = gif_newton.getAttribute("data-animated");
    gif_newton.addEventListener("mouseover", () => {
        gif_newton.src = animatedSrc_newton + "?t=" + new Date().getTime();
    });
    gif_newton.addEventListener("mouseout", () => {
      gif_newton.src = staticSrc_newton;
    });
  </script>
  <!-- NewtonDiff -->

  <!-- PixCell -->
  <div class="publication">
    <div class="publication-content"> 
      <div class="gif-container">
        <img src="content/img/pixcell.png"
             data-animated="content/img/pixcell.gif"
             alt="GIF Toggle" id="pixcellGIF">
      </div>

      <div class="text">
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2506.05127" target="_blank">
          <strong>PixCell: A generative foundation model for digital histopathology images</strong><br>
        </a>
        </p>
        <p class="authors">
        Alexandros Graikos*,
        S. Yellapragada*,
        Z. Li,
        K. Triaridis,
        V. Belagali,
        T. N. Nandi,
        K. Bai,
        B. S. Knudsen,
        T. Kurc,
        R. R. Gupta,
        P. Prasanna,
        R. K Madduri,
        J. Saltz,
        Dimitris Samaras
        </p>
        <p class="venue">
        Preprint
        </p>
        <p class="description">
        The first generative foundation model for digital histopathology images. We demonstrate the ability to preserve privacy by utilizing synthetic data, and solve generative tasks such as virtual staining.
        </p>
        <div class="links">
          <a href="https://huggingface.co/StonyBrook-CVLab/PixCell-1024" target="_blank">PixCell-1024 ðŸ¤—</a> /
          <a href="https://huggingface.co/StonyBrook-CVLab/PixCell-256" target="_blank">PixCell-256 ðŸ¤—</a> /
          <a href="https://arxiv.org/abs/2506.05127" target="_blank">arXiv</a>
        </div>
      </div>
    </div>
  </div>
  <script>
    const gif_pixcell = document.getElementById("pixcellGIF");
    const staticSrc_pixcell = gif_pixcell.src;
    const animatedSrc_pixcell = gif_pixcell.getAttribute("data-animated");
    gif_pixcell.addEventListener("mouseover", () => {
        gif_pixcell.src = animatedSrc_pixcell + "?t=" + new Date().getTime();
    });
    gif_pixcell.addEventListener("mouseout", () => {
      gif_pixcell.src = staticSrc_pixcell;
    });
  </script>
  <!-- PixCell -->

  <!-- ZoomLDM -->
  <div class="publication">
    <div class="publication-content"> 
      <div class="gif-container">
        <img src="content/img/zoomldm.png"
             data-animated="content/img/zoomldm.gif"
             alt="GIF Toggle" id="zoomldmGIF">
      </div>

      <div class="text">
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2411.16969" target="_blank">
            <strong>ZoomLDM: Latent Diffusion Model for multi-scale image generation</strong><br>
        </a>
        </p>
        <p class="authors">
        Alexandros Graikos*,
        Srikar Yellapragada*,
        Kostas Triaridis,
        Prateek Prasanna,
        Rajarsi R. Gupta,
        Joel Saltz,
        Dimitris Samaras
        </p>
        <p class="venue">
        CVPR, 2025
        </p>
        <p class="description">
        We propose a multi-scale diffusion model to make generation of massive pathology images feasible.
        </p>
        <div class="links">
          <a href="https://github.com/cvlab-stonybrook/ZoomLDM" target="_blank">Code</a> /
          <a href="https://arxiv.org/abs/2411.16969" target="_blank">arXiv</a> /
          <a href="https://histodiffusion.github.io/pages/zoomldm_large_images/large_images.html" target="_blank">Large Image Viewer</a>
        </div>
      </div>
    </div>
  </div>
  <script>
    const gif_zoomldm = document.getElementById("zoomldmGIF");
    const staticSrc_zoomldm = gif_zoomldm.src;
    const animatedSrc_zoomldm = gif_zoomldm.getAttribute("data-animated");
    gif_zoomldm.addEventListener("mouseover", () => {
        gif_zoomldm.src = animatedSrc_zoomldm + "?t=" + new Date().getTime();
    });
    gif_zoomldm.addEventListener("mouseout", () => {
      gif_zoomldm.src = staticSrc_zoomldm;
    });
  </script>
  <!-- ZoomLDM -->

  <!-- CVPR24 -->
  <div class="publication">
    <div class="publication-content"> 
      <div class="gif-container">
        <img src="content/img/cvpr24.png"
             data-animated="content/img/cvpr24.gif"
             alt="GIF Toggle" id="cvpr24GIF">
      </div>

      <div class="text">
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2312.07330" target="_blank">
          <strong>Learned representation-guided diffusion models for large-image generation</strong><br>
        </a>
        </p>
        <p class="authors">
        Alexandros Graikos*,
        Srikar Yellapragada*,
        Minh-Quan Le,
        Saarthak Kapse,
        Prateek Prasanna,
        Joel Saltz,
        Dimitris Samaras
        </p>
        <p class="venue">
        CVPR, 2024
        </p>
        <p class="description">
        We use self-supervised models to provide annotations for diffusion models in digital pathology. Exploiting the unique structure of the data, we synthesize large images with only a patch-based model.
        </p>
        <div class="links">
          <a href="https://github.com/cvlab-stonybrook/Large-Image-Diffusion" target="_blank">Code</a> /
          <a href="https://arxiv.org/abs/2312.07330" target="_blank">arXiv</a>
        </div>
      </div>
    </div>
  </div>
  <script>
    const gif_cvpr24 = document.getElementById("cvpr24GIF");
    const staticSrc_cvpr24 = gif_cvpr24.src;
    const animatedSrc_cvpr24 = gif_cvpr24.getAttribute("data-animated");
    gif_cvpr24.addEventListener("mouseover", () => {
        gif_cvpr24.src = animatedSrc_cvpr24 + "?t=" + new Date().getTime();
    });
    gif_cvpr24.addEventListener("mouseout", () => {
      gif_cvpr24.src = staticSrc_cvpr24;
    });
  </script>
  <!-- CVPR24 -->

  <!-- Denoiser Representations -->
  <div class="publication">
    <div class="publication-content"> 
      <div class="gif-container">
        <img src="content/img/denoiserrepr.png"
             data-animated="content/img/denoiserrepr.gif"
             alt="GIF Toggle" id="denoiserreprGIF">
      </div>

      <div class="text">
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2306.1900" target="_blank">
          <strong>Conditional Generation from Unconditional Diffusion Models using Denoiser Representations</strong><br>
        </a>
        </p>
        <p class="authors">
        Alexandros Graikos, 
        Srikar Yellapragada,
        Dimitris Samaras
        </p>
        <p class="venue">
        BMVC, 2023
        </p>
        <p class="description">
        We show that we can learn to control generation with as few as 20 examples using the existing denoiser representations.
        </p>
        <div class="links">
          <a href="https://github.com/cvlab-stonybrook/fewshot-conditional-diffusion" target="_blank">Code</a> / 
          <a href="https://arxiv.org/abs/2306.1900" target="_blank">arXiv</a>
        </div>
      </div>
    </div>
  </div>
  <script>
    const gif_denoiserrepr = document.getElementById("denoiserreprGIF");
    const staticSrc_denoiserrepr = gif_denoiserrepr.src;
    const animatedSrc_denoiserrepr = gif_denoiserrepr.getAttribute("data-animated");
    gif_denoiserrepr.addEventListener("mouseover", () => {
        gif_denoiserrepr.src = animatedSrc_denoiserrepr + "?t=" + new Date().getTime();
    });
    gif_denoiserrepr.addEventListener("mouseout", () => {
      gif_denoiserrepr.src = staticSrc_denoiserrepr;
    });
  </script>
  <!-- Denoiser Representations -->

  <!-- Plug-and-play -->
  <div class="publication">
    <div class="publication-content"> 
      <div class="gif-container">
        <img src="content/img/tsp_solution.png"
             data-animated="content/img/tsp_solution.gif"
             alt="GIF Toggle" id="tspGIF">
      </div>

      <div class="text">
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2206.09012" target="_blank">
          <strong>Diffusion models as plug-and-play priors</strong><br>
        </a>
        </p>
        <p class="authors">
        Alexandros Graikos, 
        Nikolay Malkin,
        Nebojsa Jojic,
        Dimitris Samaras
        </p>
        <p class="venue">
        NeurIPS 2022
        </p>
        <p class="description">
        Diffusion models can be used in inference tasks without any additional training. You can even solve the traveling salesman problem with a diffusion model (left).
        </p>
        <div class="links">
          <a href="https://github.com/AlexGraikos/diffusion_priors" target="_blank">Code</a> / 
          <a href="https://arxiv.org/abs/2206.09012" target="_blank">arXiv</a>
        </div>
      </div>
    </div>
  </div>
  <script>
    const gif_tsp = document.getElementById("tspGIF");
    const staticSrc_tsp = gif_tsp.src;
    const animatedSrc_tsp = gif_tsp.getAttribute("data-animated");
    gif_tsp.addEventListener("mouseover", () => {
      gif_tsp.src = animatedSrc_tsp + "?t=" + new Date().getTime();
    });
    gif_tsp.addEventListener("mouseout", () => {
      gif_tsp.src = staticSrc_tsp;
    });
  </script>
  <!-- Plug-and-play -->

  <!-- Food volume estimation -->
  <div class="publication">
    <div class="publication-content"> 
      <div class="gif-container">
        <img src="content/img/food_vol_est.png"
             data-animated="content/img/food_vol_est.gif"
             alt="GIF Toggle" id="foodGIF">
      </div>

      <div class="text">
        <p class="papertitle">
        <a href="https://link.springer.com/chapter/10.1007/978-3-030-49108-6_38" target="_blank">
          <strong>Single-Image Based Food Volume Estimation</strong><br>
        </a>
        </p>
        <p class="authors">
        Alexandros Graikos, 
        Vasileios Charisis,
        Dimitrios Iakovakis, 
        Stelios Hadjidimitriou, 
        Leontios Hadjileontiadis
        </p>
        <p class="venue">
        HCI International 2020
        </p>
        <p class="description">
        Training and applying monocular depth estimation models to estimate the food volume from a given RGB image.
        </p>
        <div class="links">
          <a href="https://github.com/AlexGraikos/food_volume_estimation" target="_blank">Code</a> / 
          <a href="https://link.springer.com/chapter/10.1007/978-3-030-49108-6_38" target="_blank">Paper</a>
        </div>
      </div>
    </div>
  </div>
  <script>
    const gif_food = document.getElementById("foodGIF");
    const staticSrc_food = gif_food.src;
    const animatedSrc_food = gif_food.getAttribute("data-animated");
    gif_food.addEventListener("mouseover", () => {
      gif_food.src = animatedSrc_food + "?t=" + new Date().getTime();
    });
    gif_food.addEventListener("mouseout", () => {
      gif_food.src = staticSrc_food;
    });
  </script>
  <!-- Food volume estimation -->

  <!-- Monodepth -->
  <div class="publication">
    <div class="publication-content"> 
      <div class="gif-container">
        <img src="content/img/monocular_depth_estimation.png"
             data-animated="content/img/monocular_depth_estimation.gif"
             alt="GIF Toggle" id="monodepthGIF">
      </div>

      <div class="text">
        <p class="papertitle">
        <a href="https://github.com/AlexGraikos/adversarial_depth_estimation" target="_blank">
        <strong>Monocular Depth Estimation using Generative Adversarial Networks</strong><br>
        </a>
        </p>
        <p class="authors">
        Alexandros Graikos,
        Anastasios Delopoulos
        </p>
        <p class="venue">
        Undergraduate Thesis, 2018
        </p>
        <p class="description">
        Adding GAN losses to monocular depth estimation models improves predicted depth accuracy.
        </p>
        <div class="links">
          <a href="https://github.com/AlexGraikos/adversarial_depth_estimation" target="_blank">Code</a>
        </div>
      </div>
    </div>
  </div>
  <script>
    const gif_monodepth = document.getElementById("monodepthGIF");
    const staticSrc_monodepth = gif_monodepth.src;
    const animatedSrc_monodepth = gif_monodepth.getAttribute("data-animated");
    gif_monodepth.addEventListener("mouseover", () => {
      gif_monodepth.src = animatedSrc_monodepth + "?t=" + new Date().getTime();
    });
    gif_monodepth.addEventListener("mouseout", () => {
      gif_monodepth.src = staticSrc_monodepth;
    });
  </script>
  <!-- Monodepth -->


  <!-- Listing all papers here -->

  <div class="header-panel">
    <h1 class="header">Papers</h1>
  </div>

  <div class="publication">
    <div class="publication-content"> 
      <div class="text">
        <tr>
            <strong><u>2026</u></strong>
        </tr>

        <tr>
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2410.18804" target="_blank">
          <strong>Generating metamers of human scene understanding</strong><br>
        </a>
        </p>
        <p>
        Ritik Raina,
        Abe Leite,
        <u>Alexandros Graikos</u>,
        Seoyoung Ahn,
        Dimitris Samaras,
        Greg Zelinsky
        <br>
        <i>ICLR, 2026</i><br>
        </p>
        </tr>
        

        <tr>
            <strong><u>2025</u></strong>
        </tr>

        <tr>
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2410.18804" target="_blank">
          <strong>Fast constrained sampling in pre-trained diffusion models</strong><br>
        </a>
        </p>
        <p>
        <u>Alexandros Graikos</u>,
        Nebojsa Jojic,
        Dimitris Samaras
        <br>
        <i>NeurIPS, 2025</i><br>
        </p>
        </tr>

        <tr>
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2506.05127" target="_blank">
            <strong>PixCell: A generative foundation model for digital histopathology images</strong><br>
        </a>
        </p>
        <p>
        <u>Alexandros Graikos</u>*, S. Yellapragada*, Z. Li, K. Triaridis, V. Belagali, T. N. Nandi, K. Bai, B. S. Knudsen, T. Kurc, R. R. Gupta, P. Prasanna, R. K Madduri, J. Saltz, Dimitris Samaras
        <br>
        <i>Preprint</i><br>
        </p>
        </tr>

        <tr>
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2503.11591" target="_blank">
            <strong>Pathology Image Compression with Pre-trained Autoencoders</strong><br>
        </a>
        </p>
        <p>
        Srikar Yellapragada,
        <u>Alexandros Graikos</u>,
        Kostas Triaridis,
        Zilinghan Li,
        Tarak Nath Nandi,
        Ravi K Madduri,
        Prateek Prasanna,
        Joel Saltz,
        Dimitris Samaras
        <br>
        <i>MICCAI, 2025</i><br>
        </p>
        </tr>

        <tr>
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2504.06950" target="_blank">
            <strong>PathSegDiff: Pathology Segmentation using Diffusion model representations</strong><br>
        </a>
        </p>
        <p>
        Sachin Kumar Danisetty,
        <u>Alexandros Graikos</u>, 
        Srikar Yellapragada,
        Dimitris Samaras
        <br>
        <i>5th Deep Generative Models Workshop @ MICCAI 2025</i><br>
        </p>
        </tr>

    
        <tr>
        <p class="papertitle">
        <a href="https://2025.ccneuro.org/abstract_pdf/Raina_2025_Seen2Scene_generative_model_fixation-by-fixation_scene_understanding.pdf" target="_blank">
            <strong>Seen2Scene: a generative model of fixation-by-fixation scene understanding</strong><br>
        </a>
        </p>
        <p>
        Ritik Raina,
        Abe Leite,
        <u>Alexandros Graikos</u>, 
        Seoyoung Ahn,
        Greg Zelinsky
        <br>
        <i>CCN, 2025</i><br>
        </p>
        </tr>

        <tr>
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2411.16969" target="_blank">
            <strong>ZoomLDM: Latent Diffusion Model for multi-scale image generation</strong><br>
        </a>
        </p>
        <p>
        <u>Alexandros Graikos</u>*,
        Srikar Yellapragada*,
        Kostas Triaridis,
        Prateek Prasanna,
        Rajarsi R. Gupta,
        Joel Saltz,
        Dimitris Samaras
        <br>
        <i>CVPR, 2025</i><br>
        </p>
        </tr>

        <tr>
            <strong><u>2024</u></strong>
        </tr>

        <tr>
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2412.01672" target="_blank">
            <strong>Gen-SIS: Generative Self-augmentation Improves Self-supervised Learning</strong><br>
        </a>
        </p>
        <p>
        Varun Belagali*,
        Srikar Yellapragada*,
        <u>Alexandros Graikos</u>, 
        Saarthak Kapse,
        Zilinghan Li,
        Tarak Nath Nandi,
        Ravi K Madduri,
        Prateek Prasanna,
        Joel Saltz,
        Dimitris Samaras
        <br>
        <i>Preprint</i><br>
        </p>
        </tr>

        <tr>
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2407.14709" target="_blank">
          <strong>âˆž-Brush: Controllable Large Image Synthesis with Diffusion Models in Infinite Dimensions</strong><br>
        </a>
        </p>
        <p>
        Minh-Quan Le*,
        <u>Alexandros Graikos</u>*, 
        Srikar Yellapragada,
        Rajarsi Gupta, 
        Joel Saltz,
        Dimitris Samaras
        <br>
        <i>ECCV, 2024</i><br>
        </p>
        </tr>

        <tr>
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2406.02774" target="_blank">
          <strong>Diffusion-Refined VQA Annotations for Semi-Supervised Gaze Following</strong><br>
        </a>
        </p>
        <p>
        Qiaomu Miao,
        <u>Alexandros Graikos</u>, 
        Jingwei Zhang,
        Sounak Mondal,
        Minh Hoai,
        Dimitris Samaras
        <br>
        <i>ECCV, 2024</i><br>
        </p>
        </tr>

        <tr>
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2312.07330" target="_blank">
          <strong>Learned representation-guided diffusion models for large-image generation</strong><br>
        </a>
        </p>
        <p>
        <u>Alexandros Graikos</u>*, 
        Srikar Yellapragada*,
        Minh-Quan Le,
        Saarthak Kapse,
        Prateek Prasanna,
        Joel Saltz,
        Dimitris Samaras
        <br>
        <i>CVPR, 2024</i><br>
        </p>
        </tr>

        <tr>
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2309.00748" target="_blank">
          <strong>PathLDM: Text conditioned Latent Diffusion Model for Histopathology</strong><br>
        </a>
        </p>
        <p>
        Srikar Yellapragada*,
        <u>Alexandros Graikos</u>*, 
        Prateek Prasanna,
        Tahsin Kurc,
        Joel Saltz,
        Dimitris Samaras
        <br>
        <i>WACV, 2024</i><br>
        </p>
        </tr>

        <tr>
            <strong><u>2023</u></strong>
        </tr>

        <tr>
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2306.1900" target="_blank">
          <strong>Conditional Generation from Unconditional Diffusion Models using Denoiser Representations</strong><br>
        </a>
        </p>
        <p>
        <u>Alexandros Graikos</u>, 
        Srikar Yellapragada,
        Dimitris Samaras
        <br>
        <i>BMVC, 2023</i><br>
        </p>
        </tr>

        <tr>
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2303.17712" target="_blank">
          <strong>S-volsdf: Sparse multi-view stereo regularization of neural implicit surfaces</strong><br>
        </a>
        </p>
        <p>
        Haoyu Wu,
        <u>Alexandros Graikos</u>,
        Dimitris Samaras
        <br>
        <i>ICCV, 2023</i><br>
        </p>
        </tr>

        <tr>
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2302.06576" target="_blank">
          <strong>GFlowNet-EM for learning compositional latent variable models</strong><br>
        </a>
        </p>
        <p>
        Edward Hu,
        Nikolay Malkin,
        Moksh Jain, 
        Katie Everett,
        <u>Alexandros Graikos</u>, 
        Yoshua Bengio
        <br>
        <i>ICML, 2023</i><br>
        </p>
        </tr>

        <tr>
            <strong><u>2022</u></strong>
        </tr>

        <tr>
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2206.09012" target="_blank">
          <strong>Diffusion models as plug-and-play priors</strong><br>
        </a>
        </p>
        <p>
        <u>Alexandros Graikos</u>, 
        Nikolay Malkin,
        Nebojsa Jojic,
        Dimitris Samaras
        <br>
        <i>NeurIPS, 2022</i><br>
        </p>
        </tr>

        <table>
        <tr>
        <p class="papertitle">
        <a href="https://arxiv.org/abs/2202.14000" target="_blank">
          <strong>Resolving label uncertainty with implicit generative models</strong><br>
        </a>
        </p>
        <p>
        Esther Rolf,
        Nikolay Malkin,
        <u>Alexandros Graikos</u>,
        Ana Jojic,
        Caleb Robinson,
        Nebojsa Jojic
        <br>
        <i>UAI, 2022</i><br>
        </p>
        </tr>

        <tr>
            <strong><u>2020</u></strong>
        </tr>

        <tr>
        <p class="papertitle">
        <a href="https://link.springer.com/chapter/10.1007/978-3-030-49108-6_38" target="_blank">
          <strong>Single-Image Based Food Volume Estimation</strong><br>
        </a>
        </p>
        <p>
        <u>Alexandros Graikos</u>, 
        Vasileios Charisis,
        Dimitrios Iakovakis, 
        Stelios Hadjidimitriou, 
        Leontios Hadjileontiadis
        <br>
        <i>HCI International, 2020</i><br>
        </p>
        </tr>
      </div>
    </div>
  </div>

</body>
</html>

